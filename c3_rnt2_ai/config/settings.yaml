profiles:
  dev_small:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 256
      layers: 4
      heads: 4
      vocab_size: 1024
      mtp_k: 0
      compile_step: false
      compile_local_mixer_step: false
    vortex_model:
      window_size: 128
      latent_slots: 64
      lava_top_k: 4
      lava_clusters: 0
      lava_cluster_top: 1
      lava_read_every: 1
      lava_write_every: 1
      lava_write_on_surprise: false
      lava_surprise_threshold: 0.0
      lava_state_path: data/memory/lava_state.pt
      lava_state_autoload: false
      local_mixer_kernel: 5
      ssm_state_size: 128
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
      entropy_top_k: 64
      penalty_window: 512
      top_p_min_k: 128
      top_p_max_k: 512
      exact_copy_mode: false
      escape_restrict: false
      use_mtp: true
    kv:
      window_size: 128
      kv_quant_bits: 8
      latent_slots: 32
    c3:
      tile_size: 128
      cache_vram_budget_mb: 2048
      prefetch_depth: 2
      compression: zstd
      pinned_memory: true
    depth_gating:
      enabled: false
      min_depth: 2
      max_depth: 4
      hysteresis: 0.2
      entropy_threshold: 3.5
      entropy_top_k: 64
      compute_cost_weight: 0.0
      smoothness: 1.0
    router:
      top_k: 2
      stability_threshold: 0.1
      mem_cost_weight: 0.01
      enabled: false
      weights:
        speed: 1.0
        vram: 0.01
        error: 5.0
        quality: 1.0
    agent:
      web_allowlist: ["github.com", "docs.python.org", "pytorch.org", "duckduckgo.com"]
      tools_enabled: ["run_tests", "search_web", "edit_repo", "open_docs"]
    tools:
      web:
        enabled: false
        allow_domains: ["github.com", "docs.python.org", "pytorch.org", "duckduckgo.com"]
        max_bytes: 512000
        timeout_s: 10
        rate_limit_per_min: 30
        cache_dir: data/web_cache
        cache_ttl_s: 3600
        allow_content_types: ["text/", "application/json"]
    knowledge:
      embedding_backend: auto
      embedding_model: sentence-transformers/all-MiniLM-L6-v2
      index_backend: auto
      policy:
        min_quality: 0.0
        max_age_days: null
        allow_domains: null
        deny_domains: null
        allow_source_kinds: null
        deny_source_kinds: null
    self_patch:
      enabled: false
      auto_sandbox: true
      queue_dir: data/self_patch/queue
      sandbox_dir: data/self_patch/sandbox
      max_patch_kb: 128
      run_tests_on_apply: true
      allowed_commands: ["pytest", "ruff", "python"]
      allowed_paths: ["src/", "tests/"]
      forbidden_globs: [".env", ".env.*", "data/**", "*.key", "*.pem", "*.p12", "*.sqlite", "*.db", "keys/**", "secrets/**", "src/c3rnt2/self_patch/**", "src/c3rnt2/selfimprove/**"]
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
      knowledge_path: data/continuous/knowledge.sqlite
      ingest_web: true
      ingest_urls:
        - "https://docs.python.org/3/"
        - "https://pytorch.org/docs/stable/"
      ingest:
        max_files_per_tick: 100
        max_bytes_per_file: 1048576
        max_total_bytes_per_tick: 5242880
        web:
          cooldown_minutes: 60
          sanitize:
            max_chars: 2000
            max_instruction_density: 0.04
            max_repeat_lines: 2
      trigger:
        enabled: true
        min_new_docs: 1
        min_novelty: 0.2
        min_successes: 0
      filter:
        min_quality: 0.35
        max_repeat_ratio: 0.8
        min_chars: 200
        min_novelty: 0.2
        quarantine_limit: 200
      replay:
        path: data/continuous/replay.sqlite
        max_items: 2000
        top_frac: 0.7
        random_frac: 0.3
        sample_size: 64
        seed_chunks: 40
      source_weights:
        episode: 2.0
        web: 1.0
        memory: 0.8
        logs: 0.3
        unknown: 1.0
      eval:
        anchors_path: data/continuous/anchors.jsonl
        max_regression: 0.2
        min_improvement: 0.0
      adapters:
        rank: 4
        alpha: 1.0
        target_modules: ["lm_head", "fc", "proj", "gate", "read_proj", "addr_proj", "out_proj", "in_proj"]
        strict_target_modules: false
      consolidation:
        enabled: false
        every_n_runs: 10
        top_n: 3
        weights:
          loss: 1.0
          anchors: 1.0
          episodes: 0.2
    rag:
      enabled: false
      top_k: 3
      max_chars: 1200
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  qwen8b_base:
    base_profile: dev_small
    core:
      backend: hf
      hf_model: "Qwen/Qwen2.5-8B-Instruct"
      hf_load_in_4bit: true
      hf_device: cuda
      hf_attn_implementation: sdpa
      hf_system_prompt: "You are a helpful coding assistant."
      hf_use_latest_adapter: true
      dtype: bf16
      backend_fallback: vortex
      vram_threshold_mb: 1200
      vram_floor_tokens: 32
      vram_ceil_tokens: 512
    server:
      auto_reload_adapter: false
      reload_interval_s: 60
      maintenance_window_s: 10
    decode:
      max_new_tokens: 128
    runtime:
      paged_lm_head: false

  rtx4080_16gb:
    # RTX 4080 16GB + Ryzen 7800X3D (HF Qwen-8B)
    base_profile: qwen8b_base
    core:
      hf_load_in_4bit: true
      hf_device: cuda
      hf_attn_implementation: sdpa
      dtype: bf16
      backend_fallback: vortex
    decode:
      max_new_tokens: 256

  qwen8b_train:
    base_profile: qwen8b_base
    server:
      block_during_training: true
      maintenance_window_s: 10
    hf_train:
      enabled: true
      model_name: "Qwen/Qwen2.5-8B-Instruct"
      registry_dir: data/registry/hf_train
      dataset_path: data/registry/hf_train/sft_samples.jsonl
      state_path: data/registry/hf_train/state.json
      max_samples: 128
      min_quality: 0.3
      prompt_template: "Context:\n{text}\nAnswer:"
      max_seq_len: 1024
      micro_batch_size: 1
      grad_accum_steps: 8
      max_steps: 100
      lr: 2.0e-4
      load_in_4bit: true
      load_in_8bit: false
      quant_type: nf4
      double_quant: true
      compute_dtype: bf16
      gradient_checkpointing: true
      lora_rank: 8
      lora_alpha: 16
      lora_dropout: 0.05
      target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
      use_weighted_sampling: true
      source_kind_weights:
        chat_feedback: 1.5
        chat_feedback_soft: 0.7
        episode: 1.2
        web: 0.8
        logs: 0.8

  core_only:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 512
      layers: 6
      heads: 8
      vocab_size: 2048
      mtp_k: 0
      compile_step: false
      compile_local_mixer_step: false
    vortex_model:
      window_size: 256
      latent_slots: 128
      lava_top_k: 4
      lava_clusters: 0
      lava_cluster_top: 1
      lava_read_every: 1
      lava_write_every: 1
      lava_write_on_surprise: false
      lava_surprise_threshold: 0.0
      lava_state_path: data/memory/lava_state.pt
      lava_state_autoload: false
      local_mixer_kernel: 7
      ssm_state_size: 256
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
      entropy_top_k: 64
      penalty_window: 512
      top_p_min_k: 128
      top_p_max_k: 512
      exact_copy_mode: false
      escape_restrict: false
      use_mtp: true
    kv:
      window_size: 256
      kv_quant_bits: 8
      latent_slots: 64
    depth_gating:
      enabled: false
      min_depth: 2
      max_depth: 6
      hysteresis: 0.2
      entropy_threshold: 3.5
      entropy_top_k: 64
      compute_cost_weight: 0.0
      smoothness: 1.0
  c3_paged:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 512
      layers: 6
      heads: 8
      vocab_size: 2048
      mtp_k: 0
      compile_step: false
      compile_local_mixer_step: false
    vortex_model:
      window_size: 256
      latent_slots: 128
      lava_top_k: 4
      lava_clusters: 0
      lava_cluster_top: 1
      lava_read_every: 1
      lava_write_every: 1
      lava_write_on_surprise: false
      lava_surprise_threshold: 0.0
      lava_state_path: data/memory/lava_state.pt
      lava_state_autoload: false
      local_mixer_kernel: 7
      ssm_state_size: 256
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
      entropy_top_k: 64
      penalty_window: 512
      top_p_min_k: 128
      top_p_max_k: 512
      exact_copy_mode: false
      escape_restrict: false
      use_mtp: true
    kv:
      window_size: 256
      kv_quant_bits: 8
      latent_slots: 64
    c3:
      tile_size: 128
      cache_vram_budget_mb: 4096
      paged_lm_head_stream_topk: 64
      prefetch_depth: 4
      compression: zstd
      pinned_memory: true
    depth_gating:
      enabled: false
      min_depth: 2
      max_depth: 6
      hysteresis: 0.2
      entropy_threshold: 3.5
      entropy_top_k: 64
      compute_cost_weight: 0.0
      smoothness: 1.0
    router:
      top_k: 4
      stability_threshold: 0.15
      mem_cost_weight: 0.02
      enabled: false
      weights:
        speed: 1.0
        vram: 0.01
        error: 5.0
        quality: 1.0
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  agent:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 256
      layers: 4
      heads: 4
      vocab_size: 1024
      mtp_k: 0
      compile_step: false
      compile_local_mixer_step: false
    vortex_model:
      window_size: 128
      latent_slots: 64
      lava_top_k: 4
      lava_clusters: 0
      lava_cluster_top: 1
      lava_read_every: 1
      lava_write_every: 1
      lava_write_on_surprise: false
      lava_surprise_threshold: 0.0
      lava_state_path: data/memory/lava_state.pt
      lava_state_autoload: false
      local_mixer_kernel: 5
      ssm_state_size: 128
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
      entropy_top_k: 64
      penalty_window: 512
      top_p_min_k: 128
      top_p_max_k: 512
      exact_copy_mode: false
      escape_restrict: false
      use_mtp: true
    kv:
      window_size: 128
      kv_quant_bits: 8
      latent_slots: 32
    depth_gating:
      enabled: false
      min_depth: 2
      max_depth: 4
      hysteresis: 0.2
      entropy_threshold: 3.5
      entropy_top_k: 64
      compute_cost_weight: 0.0
      smoothness: 1.0
    agent:
      web_allowlist: ["github.com", "docs.python.org", "pytorch.org", "duckduckgo.com"]
      tools_enabled: ["run_tests", "search_web", "edit_repo", "open_docs"]
    tools:
      web:
        enabled: false
        allow_domains: ["github.com", "docs.python.org", "pytorch.org", "duckduckgo.com"]
        max_bytes: 512000
        timeout_s: 10
        rate_limit_per_min: 30
        cache_dir: data/web_cache
        cache_ttl_s: 3600
        allow_content_types: ["text/", "application/json"]
    self_patch:
      enabled: false
      auto_sandbox: true
      queue_dir: data/self_patch/queue
      sandbox_dir: data/self_patch/sandbox
      max_patch_kb: 128
      run_tests_on_apply: true
      allowed_commands: ["pytest", "ruff", "python"]
      allowed_paths: ["src/", "tests/"]
      forbidden_globs: [".env", ".env.*", "data/**", "*.key", "*.pem", "*.p12", "*.sqlite", "*.db", "keys/**", "secrets/**", "src/c3rnt2/self_patch/**", "src/c3rnt2/selfimprove/**"]
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  rtx4080_16gb_vortexx:
    # VORTEX-Tok (reversible, tasa variable, ESC exacto)
    tokenizer:
      type: vortex_tok
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_tok_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro:
        enabled: true
        macro_codebook_path: data/runs/vortex_macro.pt
        max_merge: 8
        min_freq: 50

    # VORTEX-X core (V-Blocks + LAVA + SSM)
    core:
      arch: vortex_x
      precision: bf16
      compile: true
      compile_step: false
      compile_local_mixer_step: false
      hidden_size: 768
      layers: 16
      heads: 12
      mlp_ratio: 4
      dropout: 0.0
      mtp_k: 4

      local_window: 1024
      lava_slots: 256
      lava_top_k: 8
      lava_clusters: 64
      lava_cluster_top: 2
      lava_read_every: 1
      lava_write_every: 1
      lava_write_on_surprise: false
      lava_surprise_threshold: 0.0
      lava_state_path: data/memory/lava_state.pt
      lava_state_autoload: false
      lava_addr_dim: 128

      ssm:
        enabled: true
        state_dim: 256
        scan_chunk: 256

    # KV antiguo: úsalo solo como “ventana local” si lo mantienes
    kv:
      window_size: 1024
      kv_quant_bits: 8
      latent_slots: 0

    # Runtime “VRAM como caché” (C3 tiles)
    c3:
      tile_size: 128
      cache_vram_budget_mb: 10000
      prefetch_depth: 4
      compression: zstd
      pinned_memory: true

    router:
      top_k: 4
      stability_threshold: 0.15
      mem_cost_weight: 0.02
      enabled: false
      weights:
        speed: 1.0
        vram: 0.01
        error: 5.0
        quality: 1.0
      hysteresis: 0.1

    decode:
      method: bad
      draft_block: 8
      verify: true
      temperature: 0.7
      top_p: 0.95
      exact_copy_mode: false
      escape_restrict: false
      use_mtp: true
      max_new_tokens: 512
      adaptive_granularity: true
      entropy_top_k: 64
      penalty_window: 512
      top_p_min_k: 128
      top_p_max_k: 512

    depth_gating:
      enabled: true
      min_depth: 8
      max_depth: 16
      hysteresis: 0.2
      entropy_threshold: 3.5
      entropy_top_k: 64
      compute_cost_weight: 0.0
      smoothness: 1.0

    agent:
      web_allowlist:
        - "github.com"
        - "docs.python.org"
        - "pytorch.org"
        - "duckduckgo.com"
        - "developer.nvidia.com"
      tools_enabled: ["run_tests", "search_web", "open_docs", "propose_patch"]
      rate_limit_per_min: 30

  rtx4080_16gb_vortexx_next:
    base_profile: rtx4080_16gb_vortexx
    core:
      cuda_graphs: true
    vortex_model:
      lava_ann_mode: ivf
      lava_cluster_ema: 0.1
      lava_cluster_reassign_threshold: 0.05
      lava_shared_groups: 4
      lava_write_every: 2
    decode:
      draft_model:
        enabled: true
        draft_layers: 6
        draft_hidden: 512
        share_embeddings: true
        share_lm_head: true
    runtime:
      paged_lm_head: true
      paged_tile_out: 256
      paged_tile_in: 768
      cache_vram_budget_mb: 4096
      paged_lm_head_stream_topk: 64
      prefetch_depth: 4
      compression: zstd
      pinned_memory: true

  safe_selftrain_4080:
    base_profile: rtx4080_16gb_vortexx

    continuous:
      enabled: true
      interval_minutes: 30
      max_steps_per_tick: 200
      lr: 1.0e-4
      batch_tokens: 8192
      knowledge_path: data/continuous/knowledge.sqlite
      ingest_web: true
      ingest:
        max_files_per_tick: 200
        max_bytes_per_file: 2097152
        max_total_bytes_per_tick: 10485760
        web:
          cooldown_minutes: 60
          sanitize:
            max_chars: 2000
            max_instruction_density: 0.04
            max_repeat_lines: 2
      adapters:
        type: lora
        rank: 16
        alpha: 32
        target_modules: ["linear", "proj"]
        strict_target_modules: false
      trigger:
        enabled: true
        min_new_docs: 1
        min_novelty: 0.2
        min_successes: 0
      filter:
        min_quality: 0.35
        max_repeat_ratio: 0.8
        min_chars: 200
        min_novelty: 0.2
        quarantine_limit: 200
      replay:
        path: data/continuous/replay.sqlite
        max_items: 5000
        top_frac: 0.7
        random_frac: 0.3
        sample_size: 128
        seed_chunks: 80
      source_weights:
        episode: 2.0
        web: 1.0
        memory: 0.8
        logs: 0.3
        unknown: 1.0
      eval:
        min_improvement: 0.5
        max_regression: 0.2
        anchors_path: data/continuous/anchors.jsonl
        metrics: ["loss", "exact_copy", "json_valid", "tokens_per_sec"]
      consolidation:
        enabled: false
        every_n_runs: 10
        top_n: 3
        weights:
          loss: 1.0
          anchors: 1.0
          episodes: 0.2
      registry_dir: data/registry
      dataset_dir: data/datasets
      safety:
        forbid_self_patch_during_train: true

  selfimprove_sandbox_4080:
    base_profile: rtx4080_16gb_vortexx

    selfimprove:
      enabled: true
      sandbox_dir: data/workspaces/selfimprove
      runs_dir: data/selfimprove/runs
      require_approval: true
      approval_file: data/APPROVE_SELF_PATCH

      # política de edición (safety kernel)
      allowed_paths:
        - "c3_rnt2_ai/src/c3rnt2/"
        - "c3_rnt2_ai/tests/"
        - "c3_rnt2_ai/config/"
      forbidden_paths:
        - "c3_rnt2_ai/src/c3rnt2/selfimprove/safety_kernel.py"
        - ".git/"
      max_patch_kb: 256
      commands_allowed: ["pytest -q"]
