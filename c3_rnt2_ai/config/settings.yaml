profiles:
  dev_small:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 256
      layers: 4
      heads: 4
      vocab_size: 1024
    vortex_model:
      window_size: 128
      latent_slots: 64
      lava_top_k: 4
      local_mixer_kernel: 5
      ssm_state_size: 128
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
    kv:
      window_size: 128
      kv_quant_bits: 8
      latent_slots: 32
    c3:
      tile_size: 128
      cache_vram_budget_mb: 2048
      prefetch_depth: 2
      compression: zstd
    router:
      top_k: 2
      stability_threshold: 0.1
      mem_cost_weight: 0.01
    agent:
      web_allowlist: ["github.com", "docs.python.org", "pytorch.org"]
      tools_enabled: ["run_tests", "search_web", "edit_repo", "open_docs"]
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  core_only:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 512
      layers: 6
      heads: 8
      vocab_size: 2048
    vortex_model:
      window_size: 256
      latent_slots: 128
      lava_top_k: 4
      local_mixer_kernel: 7
      ssm_state_size: 256
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
    kv:
      window_size: 256
      kv_quant_bits: 8
      latent_slots: 64
  c3_paged:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 512
      layers: 6
      heads: 8
      vocab_size: 2048
    vortex_model:
      window_size: 256
      latent_slots: 128
      lava_top_k: 4
      local_mixer_kernel: 7
      ssm_state_size: 256
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
    kv:
      window_size: 256
      kv_quant_bits: 8
      latent_slots: 64
    c3:
      tile_size: 128
      cache_vram_budget_mb: 4096
      prefetch_depth: 4
      compression: zstd
    router:
      top_k: 4
      stability_threshold: 0.15
      mem_cost_weight: 0.02
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  agent:
    tokenizer:
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_model_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro_codebook_size: 256
      macro_min_len: 2
    core:
      hidden_size: 256
      layers: 4
      heads: 4
      vocab_size: 1024
    vortex_model:
      window_size: 128
      latent_slots: 64
      lava_top_k: 4
      local_mixer_kernel: 5
      ssm_state_size: 128
      gated_mlp_ratio: 4
    bad:
      block_size: 8
      entropy_threshold: 3.5
    kv:
      window_size: 128
      kv_quant_bits: 8
      latent_slots: 32
    agent:
      web_allowlist: ["github.com", "docs.python.org", "pytorch.org"]
      tools_enabled: ["run_tests", "search_web", "edit_repo", "open_docs"]
    continuous:
      run_interval_minutes: 30
      adapter_rank: 4
      max_steps: 50
    selfimprove:
      max_patch_kb: 64
      sandbox_root: data/workspaces
  rtx4080_16gb_vortexx:
    # VORTEX-Tok (reversible, tasa variable, ESC exacto)
    tokenizer:
      type: vortex_tok
      rnt2_model_path: data/runs/rnt2_dev.pt
      vortex_tok_path: data/runs/vortex_tok.pt
      block_size: 64
      escape_mode: exact
      macro:
        enabled: true
        macro_codebook_path: data/runs/vortex_macro.pt
        max_merge: 8
        min_freq: 50

    # VORTEX-X core (V-Blocks + LAVA + SSM)
    core:
      arch: vortex_x
      precision: bf16
      compile: true
      hidden_size: 768
      layers: 16
      heads: 12
      mlp_ratio: 4
      dropout: 0.0

      local_window: 1024
      lava_slots: 256
      lava_top_k: 8
      lava_addr_dim: 128

      ssm:
        enabled: true
        state_dim: 256
        scan_chunk: 256

    # KV antiguo: úsalo solo como “ventana local” si lo mantienes
    kv:
      window_size: 1024
      kv_quant_bits: 8
      latent_slots: 0

    # Runtime “VRAM como caché” (C3 tiles)
    c3:
      tile_size: 128
      cache_vram_budget_mb: 10000
      prefetch_depth: 4
      compression: zstd

    router:
      top_k: 4
      stability_threshold: 0.15
      mem_cost_weight: 0.02
      hysteresis: 0.1

    decode:
      method: bad
      draft_block: 8
      verify: true
      temperature: 0.7
      top_p: 0.95
      max_new_tokens: 512
      adaptive_granularity: true

    agent:
      web_allowlist:
        - "github.com"
        - "docs.python.org"
        - "pytorch.org"
        - "developer.nvidia.com"
      tools_enabled: ["run_tests", "search_web", "open_docs", "propose_patch"]
      rate_limit_per_min: 30

  safe_selftrain_4080:
    base_profile: rtx4080_16gb_vortexx

    continuous:
      enabled: true
      interval_minutes: 30
      max_steps_per_tick: 200
      lr: 1.0e-4
      batch_tokens: 8192
      adapters:
        type: lora
        rank: 16
        alpha: 32
        target_modules: ["linear", "proj"]
      eval:
        min_improvement: 0.5
        metrics: ["loss", "exact_copy", "json_valid", "tokens_per_sec"]
      registry_dir: data/registry
      dataset_dir: data/datasets
      safety:
        forbid_self_patch_during_train: true

  selfimprove_sandbox_4080:
    base_profile: rtx4080_16gb_vortexx

    selfimprove:
      enabled: true
      sandbox_dir: data/workspaces/selfimprove
      runs_dir: data/selfimprove/runs
      require_approval: true
      approval_file: data/APPROVE_SELF_PATCH

      # política de edición (safety kernel)
      allowed_paths:
        - "c3_rnt2_ai/src/c3rnt2/"
        - "c3_rnt2_ai/tests/"
        - "c3_rnt2_ai/config/"
      forbidden_paths:
        - "c3_rnt2_ai/src/c3rnt2/selfimprove/safety_kernel.py"
        - ".git/"
      max_patch_kb: 256
      commands_allowed: ["pytest -q"]
