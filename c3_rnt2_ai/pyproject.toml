[project]
name = "vortex"
version = "0.1.0"
description = "Vortex local inference + training stack"
readme = "README.md"
requires-python = ">=3.10"
authors = [{name = "Local", email = "local@example.com"}]
license = {text = "MIT"}
dependencies = [
  "torch>=2.1",
  "typer>=0.9",
  "rich>=13",
  "pyyaml>=6",
  "numpy>=1.24",
  "psutil>=5.9",
  "requests>=2.31",
  "zstandard>=0.22",
  "lz4>=4.3",
  "tqdm>=4.66"
]

[project.optional-dependencies]
api = ["fastapi>=0.110", "uvicorn>=0.23"]
triton = ["triton>=2.1"]
hf = [
  # Newer transformers builds gate torch.load behind torch>=2.6 due to CVE-2025-32434;
  # keep compatibility with torch 2.5 stacks (RTX 4080) while supporting Qwen2.5.
  "transformers>=4.40,<4.57",
  "accelerate>=0.27",
  "safetensors>=0.4",
  # Required for PEFT adapters/expert bank inference.
  "peft>=0.10",
  # bitsandbytes is Linux-focused; HF can run without it on Windows.
  "bitsandbytes>=0.43; platform_system != 'Windows'",
]
experts = ["peft>=0.10"]
train = ["peft>=0.10"]
rag = [
  "sentence-transformers>=2.6",
  # Wheels are not consistently available on Windows; code falls back to non-faiss ranking.
  "faiss-cpu>=1.7; platform_system != 'Windows'",
]
llama_cpp = ["llama-cpp-python>=0.2.0"]

[project.scripts]
klimeai = "c3rnt2.__main__:main"

[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-q"
testpaths = ["tests"]

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]
